{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fa1b9f-b560-43ed-898e-cc1b4fc3ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "from scipy import stats\n",
    "import healpy as hp  # NOTE: you can neglect warning about version mismatch in CFITSIO if necessary \n",
    "\n",
    "N_side = 2048      # Both maps will have this N_side. Healpix map has 12 * N_side**2 pixels\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import emcee\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, shutil\n",
    "import random\n",
    "import sklearn.metrics as slm\n",
    "\n",
    "import corner\n",
    "from scipy.interpolate import interp1d\n",
    "%matplotlib inline\n",
    "\n",
    "pkdir = \"/pscratch/sd/s/sbrisin/boss_cib_cmass/cibcmass/hmvec\"\n",
    "sys.path.insert(0, pkdir)\n",
    "# Import hmvec as hm\n",
    "from hmvec import hmvec as hm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52148825-014d-4cbb-8446-438047023322",
   "metadata": {},
   "source": [
    "This part of the notebook is for prepping the data, getting the stuff calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd51eab-f3ea-4c70-a11d-07e602bef6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load maps \n",
    "CIB_map = hp.read_map('/pscratch/sd/s/sbrisin/boss_cib_cmass/cibcmass/notebooks/COM_CompMap_CIB-GNILC-F545_2048_R2.00(2).fits')        # read CIB map\n",
    "CIB_mask = hp.read_map('/pscratch/sd/s/sbrisin/boss_cib_cmass/catalogues/cib_mask.fits')                                    # read CIB mask\n",
    "\n",
    "CIB_masked = hp.ma(CIB_map)\n",
    "CIB_masked.mask = np.logical_not(CIB_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193216a3-9bf8-4197-a984-2e7c5c278c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ef read_nobs_pyfits(filename):\n",
    "    with fits.open(filename, memmap=True) as hdul:\n",
    "        data = (hdul[1].data)\n",
    "        return np.shape(data)[0], hdul[1].columns.names\n",
    "\n",
    "def read_test_pyfits(filename, colname):\n",
    "    with fits.open(filename, memmap=True) as hdul:\n",
    "        data = (hdul[1].data[colname])\n",
    "        return data.copy()\n",
    "\n",
    "def get_BOSS_data(gal):\n",
    "    nObs, cols = read_nobs_pyfits(gal)\n",
    "    colnames = [x for x in cols if x in ['ID', 'RA', 'DEC', 'Z', 'NZ', 'BOSS_SPECOBJ_ID',\n",
    "                                         'BOSS_TARGET1', 'BOSS_TARGET2', 'EBOSS_TARGET0', 'ZOFFSET', 'TARGETOBJID',\n",
    "                                         'OBJID', 'PLUG_RA', 'PLUG_DEC', 'Z']]\n",
    "    ncols = len(colnames)\n",
    "    myGalaxy = pd.DataFrame(data=np.zeros([nObs, ncols]), columns=colnames)\n",
    "    for rowname in myGalaxy.columns:\n",
    "        myGalaxy[rowname] = read_test_pyfits(gal, rowname).byteswap().newbyteorder()\n",
    "    print(myGalaxy.columns)\n",
    "    myGalaxy = myGalaxy.sort_values(by=['Z'])\n",
    "    return myGalaxy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "boss_catalog_path_s = '/pscratch/sd/s/sbrisin/boss_cib_cmass/cibcmass/notebooks/galaxy_DR12v5_CMASS_South (1).fits'\n",
    "boss_catalog_path_n = '/pscratch/sd/s/sbrisin/boss_cib_cmass/cibcmass/notebooks/galaxy_DR12v5_CMASS_North (1)(1).fits'\n",
    "# Load the relevant entries of the catalog (we will be mostly concerned with RA, DEC, and redshift)\n",
    "\n",
    "boss_catalog_s = get_BOSS_data(boss_catalog_path_s)\n",
    "boss_catalog_n = get_BOSS_data(boss_catalog_path_n)\n",
    "\n",
    "datas = get_BOSS_data(boss_catalog_path_s)\n",
    "datan = get_BOSS_data(boss_catalog_path_n)\n",
    "datas = pd.DataFrame(datas)\n",
    "datasmodd = pd.DataFrame(datas[(datas.Z > 0.4) * (datas.Z < .5)])\n",
    "datanmodd = pd.DataFrame(datan[(datan.Z > 0.4) * (datan.Z < .5)])\n",
    "\n",
    "modtot = pd.concat([datanmodd,datasmodd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ab96df-a943-416c-baf1-153dd059d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nside = 2048\n",
    "npix = hp.nside2npix(nside)\n",
    "c_icrs_s = SkyCoord(ra=modtot['RA']*u.degree, dec=modtot['DEC']*u.degree, frame='icrs')\n",
    "indices = hp.ang2pix(nside, c_icrs_s.galactic.l.value, c_icrs_s.galactic.b.value, lonlat=True)\n",
    "gal_hpmap = np.zeros(npix, dtype=np.float)\n",
    "np.add.at(gal_hpmap, indices, 1)\n",
    "\n",
    "def get_dn_from_map(gal_hpmap):\n",
    "    ''' Convert a galaxy number map obtained using get_map_from_catalog() to one of fractional\n",
    "        overdensity. Return also the mask\n",
    "    ''' \n",
    "    #Total number counts. Should convert to delta_n/n. Make a mask first!\n",
    "    gal_downgraded = hp.ud_grade(gal_hpmap, 64)\n",
    "    gal_mask = np.zeros(len(gal_downgraded))\n",
    "    gal_mask[(gal_downgraded > 0)] = 1\n",
    "    nside = hp.npix2nside(len(gal_hpmap))\n",
    "    gal_mask = hp.ud_grade(gal_mask, nside) # bring it back to the original resolution\n",
    "    \n",
    "    # Convert to delta_n / n (fractional fluctuations: this is what we can predict from theory)\n",
    "    mean_gal = np.sum(gal_hpmap * gal_mask) / np.sum(gal_mask)\n",
    "    gal_masked_dn = (gal_hpmap * gal_mask) / mean_gal - 1.\n",
    "    gal_masked_dn = gal_mask * gal_masked_dn\n",
    "    return gal_masked_dn, gal_mask\n",
    "\n",
    "\n",
    "gal_dn, gal_mask = get_dn_from_map(gal_hpmap)\n",
    "gal_dn.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970dff6-e112-436f-aabe-a73206127a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMASS map, total number counts. Should convert to delta_n/n. Make a mask first!\n",
    "CMASS_map = gal_hpmap # mask should be made from regular density \n",
    "CMASS_downgraded = hp.ud_grade(CMASS_map, 64)\n",
    "CMASS_mask = np.zeros(len(CMASS_downgraded))\n",
    "CMASS_mask[(CMASS_downgraded > 0)] = 1\n",
    "CMASS_mask = hp.ud_grade(CMASS_mask, N_side) # bring it back to the original resolution\n",
    "coord= ['G','C']\n",
    "# Convert to a masked array for better plotting\n",
    "CMASS_masked_dn = hp.ma(gal_dn)\n",
    "CMASS_masked_dn.mask = np.logical_not(CMASS_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353113dd-7e7f-4a16-a8d3-ef5a1b476656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"total\" mask is product of PLANCK and CMASS masks\n",
    "mask_tot = CMASS_mask * CIB_mask\n",
    "fsky = np.sum(mask_tot) / len(mask_tot) # fsky for the cross-correlation\n",
    "fsky_CIB = np.sum(CIB_mask) / len(CIB_mask)\n",
    "fsky_CMASS = np.sum(CMASS_mask) / len(CMASS_mask)\n",
    "print(\"f_sky cross = \" + str(fsky))\n",
    "print(\"f_sky CIB = \" + str(fsky_CIB))\n",
    "print(\"f_sky CMASS = \" + str(fsky_CMASS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8535869e-7aaf-4bb8-897f-7f1ecddf8203",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cl_cross = hp.anafast(CIB_masked, map2 = CMASS_masked_dn, lmax = 2000)\n",
    "ls = np.arange(len(Cl_cross))\n",
    "pixwinf = hp.pixwin(N_side)[0:len(Cl_cross)]\n",
    "# further divide by one power of beam\n",
    "Cl_cross = Cl_cross / (pixwinf **2)                # Remove pixel window function\n",
    "Cl_cross = Cl_cross / fsky                         # Undo the dilution caused by having observed only part of the sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02900ce0-7396-43c5-ae25-61f96a0ecbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as before!\n",
    "Cl_CIB = hp.anafast(CIB_masked, lmax = 2000)\n",
    "Cl_CMASS = hp.anafast(CMASS_masked_dn, lmax = 2000)\n",
    "Cl_CIB = Cl_CIB / (pixwinf **2)\n",
    "Cl_CMASS = Cl_CMASS / (pixwinf **2)\n",
    "Cl_CIB = Cl_CIB / fsky_CIB\n",
    "Cl_CMASS = Cl_CMASS / fsky_CMASS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f915f4b-efd1-4c7e-bd33-70c83da84c82",
   "metadata": {},
   "source": [
    "this is all the stuff for making the actual covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea1ba2-4ed7-4c8d-a3c9-7fcc4187d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_mat_nocib(cii,cgg,cig,l):\n",
    "    f_sky_cross = 0.249634150739921\n",
    "    f_sky_CIB = 0.5787552197774252\n",
    "    f_sky_CMASS = 0.2552083333333333\n",
    "\n",
    "    # cgg, cll, and cig are going to be the valeus pre bin?\n",
    "    var_gg = (2*cgg)/((2*l+1)*(f_sky_CMASS))\n",
    "    var_ig = (cgg*cii+cig**2)/((2*l+1)*f_sky_cross)\n",
    "    cov_cgg_cgi = (2*cgg*cig)/((2*l+1)*f_sky_CMASS)\n",
    "    a = np.array([var_gg,cov_cgg_cgi])\n",
    "    b = np.array([cov_cgg_cgi,var_ig])\n",
    "    return l,var_gg,var_ig,cov_cgg_cgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c948940-44a4-4c64-a877-35d6901a7ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ells = np.arange(300,1000)\n",
    "b = []\n",
    "for l in ells:\n",
    "    clcib_l = Cl_CIB[l]\n",
    "    clcmass_l = Cl_CMASS[l]\n",
    "    clcross_l = Cl_cross[l]\n",
    "    y = cov_mat_nocib(clcib_l,clcmass_l,clcross_l,l)\n",
    "    b.append(y)\n",
    "    \n",
    "def bins(n_bin,min_l,max_l): # calculate the bins size\n",
    "    x = []\n",
    "    b = 0\n",
    "    size = (max_l-min_l)/n_bin\n",
    "    while min_l <= 1000:\n",
    "        x.append(min_l)\n",
    "        min_l = min_l + size\n",
    "        print(min_l)\n",
    "    return np.array(x)\n",
    "\n",
    "bins(5,300,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01aa1cb4-c869-412b-ba3f-01ec1affc8b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add the stuff from the meeting yesterday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa9e05-266c-4270-b459-e93ff0584b25",
   "metadata": {},
   "source": [
    "this is for the mcmc!! THIS IS ALL FOR .4 to .5 Z bins!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3127f-eea6-4883-903a-c48b9083bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up all the HMVEC stuff\n",
    "\n",
    "ells = np.arange(3000)\n",
    "cib_freq = 545 * 1e9\n",
    "\n",
    "\n",
    "zs = np.linspace(.4, .5, 10)\n",
    "ms = np.geomspace(1e10, 1e17, 20) # revisit the webb sky, \n",
    "#lower mass limit and see if the disagreement goes away \n",
    "ks = np.geomspace(1e-4, 100, 100)\n",
    "\n",
    "hcos = hm.HaloModel(zs, ks, ms=ms)\n",
    "hcos.set_cibParams('vierro')\n",
    "\n",
    "        # a and b are the z range\n",
    "hcos.cib_params['alpha'] = 0.2\n",
    "hcos.cib_params['beta'] = 1.6\n",
    "hcos.cib_params['gamma'] = 1.7  # not in Viero, so using Planck13\n",
    "hcos.cib_params['delta'] = 2.4\n",
    "hcos.cib_params['Td_o'] = 20.7\n",
    "logmeff = hcos.cib_params['logM_eff']\n",
    "hcos.cib_params['var'] = 0.3\n",
    "l0 = hcos.cib_params['L_o']\n",
    "hcos.add_hod(name=\"CMASS\", mthresh=10**12 + zs*0.)\n",
    "ells = np.arange(300,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb69e9-8118-4279-ab99-7138b62ca228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cgg_mod(theta):\n",
    "    x,y = theta\n",
    "    gdndz = np.array([3091.0, 4697.0,7307.0,11655.0,18705.0,25476.0,\t31238.0,37006.0\t,40371.0,\t43370.0])\n",
    "    zs = np.array([0.40000978,0.41000876,0.42000774,0.4300067,0.4400057,0.45000467,0.46000364,0.47000262,0.4800016,0.49000058,0.4999995529651642])\n",
    "    hcos.cib_params['L_o'] = x\n",
    "    hcos.cib_params['logM_eff'] = y\n",
    "            # Power spectra for CIB x galaxies\n",
    "    Pgg_1h = hcos.get_power_1halo('CMASS', 'CMASS', nu_obs=np.array([cib_freq]))\n",
    "    Pgg_2h = hcos.get_power_2halo('CMASS', 'CMASS', nu_obs=np.array([cib_freq]))\n",
    "\n",
    "    Cl_gg_1h = hcos.C_gg(ells, hcos.zs, hcos.ks, Pgg_1h, gzs=zs, gdndz=gdndz)\n",
    "    Cl_gg_2h = hcos.C_gg(ells, hcos.zs, hcos.ks, Pgg_2h, gzs=zs, gdndz=gdndz)\n",
    "    \n",
    "    # need to end up with one vector thats c_gi for each l bin, c_gg for each l bin\n",
    "    tot = Cl_gg_1h + Cl_gg_2h\n",
    "    \n",
    "    b1 = tot[ells == 70]\n",
    "    b2 = tot[ells == 210]\n",
    "    b3 = tot[ells == 350] \n",
    "    b4 = tot[ells == 490.0]\n",
    "    b5 = tot[ells == 630]\n",
    "    b = np.array([b1,b2,b3,b4,b5])\n",
    "    return b\n",
    "\n",
    "def cii_mod(theta):\n",
    "    x,y = theta\n",
    "    zs = np.linspace(.01,5,20)\n",
    "    ms = np.geomspace(1e10,1e17,200)\n",
    "    ks = np.geomspace(1e-4,100,1001)\n",
    "    hcos = hm.HaloModel(zs,ks,ms=ms)\n",
    "    hcos.set_cibParams('vierro')\n",
    "    hcos.cib_params['L_o'] = x\n",
    "    hcos.cib_params['logM_eff'] = y\n",
    "            # Power spectra for CIB x galaxies\n",
    "    Pii_1h = hcos.get_power_1halo('cib', 'cib', nu_obs=np.array([cib_freq]))\n",
    "    Pii_2h = hcos.get_power_2halo('cib', 'cib', nu_obs=np.array([cib_freq]))\n",
    "\n",
    "    Cl_ii_1h = hcos.C_ii(ells, hcos.zs, hcos.ks, Pii_1h)\n",
    "    Cl_ii_2h = hcos.C_ii(ells, hcos.zs, hcos.ks, Pii_2h)\n",
    "    \n",
    "    # need to end up with one vector thats c_gi for each l bin, c_gg for each l bin\n",
    "    tot = Cl_ii_1h + Cl_ii_2h\n",
    "    \n",
    "    b1 = tot[ells == 70]\n",
    "    b2 = tot[ells == 210]\n",
    "    b3 = tot[ells == 350] \n",
    "    b4 = tot[ells == 490.0]\n",
    "    b5 = tot[ells == 630]\n",
    "    b = np.array([b1,b2,b3,b4,b5])\n",
    "    return b\n",
    "\n",
    "def cig_mod(theta):\n",
    "    x,y = theta\n",
    "    gdndz = np.array([3091.0, 4697.0,7307.0,11655.0,18705.0,25476.0,31238.0,37006.0\t,40371.0,43370.0])\n",
    "    gzs = np.array([0.40000978,0.41000876,0.42000774,0.4300067,0.4400057,0.45000467,0.46000364,0.47000262,0.4800016,0.49000058])\n",
    "    new_gdndz = np.interp(hcos.zs, gzs, gdndz, left=0, right=0)\n",
    "    hcos.cib_params['L_o'] = x\n",
    "    hcos.cib_params['logM_eff'] = y\n",
    "            # Power spectra for CIB x galaxies\n",
    "    PgI_1h = hcos.get_power_1halo('CMASS', 'cib', nu_obs=np.array([cib_freq]))\n",
    "    PgI_2h = hcos.get_power_2halo('CMASS', 'cib', nu_obs=np.array([cib_freq]))\n",
    "\n",
    "    Cl_gI_1h = hcos.C_gI(ells, hcos.zs, hcos.ks, PgI_1h, gzs=gzs, gdndz= new_gdndz)\n",
    "    Cl_gI_2h = hcos.C_gI(ells, hcos.zs, hcos.ks, PgI_2h, gzs=gzs, gdndz= new_gdndz)\n",
    "    \n",
    "    # need to end up with one vector thats c_gi for each l bin, c_gg for each l bin\n",
    "    tot = Cl_gI_1h + Cl_gI_2h\n",
    "    \n",
    "    df = pd.DataFrame({'ells': ells, 'tot': tot})\n",
    "    b1 = float(tot[ells == 370.0])\n",
    "    b2 = float(tot[ells == 510.0])\n",
    "    b3 = float(tot[ells == 650.0]) \n",
    "    b4 = float(tot[ells == 790.0])\n",
    "    b5 = float(tot[ells == 930.0])\n",
    "    b = np.array([b1,b2,b3,b4,b5])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49717f9-1b96-49c5-80e7-25e63c73b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(theta, dat = dat):\n",
    "    x,y =  theta\n",
    "    return (cig_mod(theta))\n",
    "def lnlike(theta,dat,cov,cinv):\n",
    "    x = cig_mod(theta)\n",
    "    gauss_like = -0.5*np.dot(np.dot(x-dat,cinv),x-dat)\n",
    "    return np.log(gauss_like)\n",
    "def lnprior(theta):\n",
    "    x,y = theta\n",
    "    return 0.0\n",
    "def lnprob(theta):\n",
    "    lp = lnprior(theta)\n",
    "    if lp == -np.inf:\n",
    "        return -np.inf\n",
    "    return lp + model(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87d292-c639-4d6f-a6d6-da69a6b26d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(p0,nwalkers,niter,ndim,lnprob,data):\n",
    "    sampler =  emcee.EnsembleSampler(nwalkers,ndim, lnprob, args = data)\n",
    "    print('running baybee..')\n",
    "    p0, _, _ = sampler.run_mcmc(p0,1000)\n",
    "    sampler.reset()\n",
    "    \n",
    "    print( 'running prod')\n",
    "    pos, prob, state =  sampler.run_mcmc(p0,niter)\n",
    "    print('done!')\n",
    "    return sampler, pos, prob, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5b1a21-7d16-4271-b472-c2aefd2b7f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (dat,cov,cinv)\n",
    "nwalkers = 5\n",
    "niter = 1000\n",
    "# set n walkers\n",
    "# set niter \n",
    "initial = np.array([2e-7,12.3]) # these come from the initial vierro params\n",
    "ndim = 2 # only 2 params so 2 dim\n",
    "p0 = [np.array(initial) + np.random.randn(ndim) for i in range(nwalkers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade22432-657c-46d6-8ca0-f65763f97af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler, pos, prob, state = main(p0,nwalkers,niter,ndim,lnlike,data)\n",
    "samples = sampler.flatchain\n",
    "labels = ['L_o', 'Log_Meff']\n",
    "fig = corner.corner(samples,show_titles=True,labels=labels,plot_datapoints=True,quantiles=[0.16, 0.5, 0.84])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
